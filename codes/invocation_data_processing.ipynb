{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02287f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94166fb0",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497026a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as = pd.read_csv('../data/AngOrdtext', delimiter='\\t', names=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49d80d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the date file\n",
    "# reshape the file in a format similar to the previous one\n",
    "date_as = pd.read_csv('../data/AngOrdDate', delimiter=' ', header=None).values.ravel()\n",
    "date_as = pd.DataFrame(date_as, columns=['date']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f882e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_as = pd.read_csv('../data/AngOrdID', delimiter='\\t', names=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6090a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge three df together to form a larger df contains both id, date, and text\n",
    "df_as = pd.concat([id_as, date_as, text_as], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad50a131",
   "metadata": {},
   "source": [
    "# Extract 10 Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d66ca820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a method that extract first 10 words for each text\n",
    "def extract_10(text):\n",
    "    \n",
    "    # split the text to a list by white space\n",
    "    # take the first 10 word\n",
    "    text = text.split()[: 10]\n",
    "    \n",
    "    # join the words in list to text\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1767a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function above to all text and create a new column\n",
    "df_as['phrase'] = df_as.text.apply(lambda x: extract_10(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0203518b",
   "metadata": {},
   "source": [
    "# Standerdize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "381bdcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dictionary = {\n",
    "    'aelfger': ['alfger'],\n",
    "    'altithroni': ['altitroni'],\n",
    "    'biscop': ['bisscop', 'biscopes'],\n",
    "    'christi': ['cristi'],\n",
    "    'king': ['cyng', 'cynge', 'cing', 'kingc', 'kyng', 'kyngc', 'cyngc', 'cyngcc', 'kingc', 'kinge', 'cyningc'],\n",
    "    'ðara': ['þara'],\n",
    "    'divino': ['diuino'],\n",
    "    'dominice': ['dominicae', 'dominicæ'],\n",
    "    'eadgari': ['eadgar', 'edgari', 'eadgarii'],\n",
    "    'edredi': ['eddredi', 'eadredi'],\n",
    "    'edward': ['eadweard', 'eadward' , 'eadwardus'],\n",
    "    'iesu': ['jhesu', 'jesu'],\n",
    "    'incarnationis': ['incarnacionis'],\n",
    "    'incertis': ['in certis'],\n",
    "    'indiuidue': ['indiuiduae'],\n",
    "    'inperpetuum': ['imperpetuum', 'in perpetuum', 'im perpetuum'],\n",
    "    'privilegium': ['priuilegium'],\n",
    "    'quamvis': ['quamuis'],\n",
    "    'salvatoris': ['saluatoris'],\n",
    "    'sancte': ['sanctae', 'sanctæ'],\n",
    "    'seculi': ['sæculi'],\n",
    "    'swutelath': ['swutelaþ', 'swutelað'],\n",
    "    'thare': ['þære', 'þare'],\n",
    "    'thisum': ['þissum', 'þisum'],\n",
    "    'verba': ['uerba'],\n",
    "    'universis': ['uniuersis']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7af8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standerdize(sentence, word_map):\n",
    "    # loop over dictionary\n",
    "    for key, values in word_map.items():\n",
    "        # loop over word inside value\n",
    "        for word in values:\n",
    "            if word in sentence:\n",
    "                sentence = sentence.replace(word, key)\n",
    "    # replace other letters\n",
    "    word_map2 = {'æ': 'e', 'ae': 'e', 'ð': 'th', 'þ': 'th'}\n",
    "    for old, new in word_map2.items():\n",
    "        sentence = sentence.replace(old, new)\n",
    "    return sentence      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f265837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_as.phrase = df_as.phrase.apply(lambda x: standerdize(x, word_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9727dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_as.text = df_as.text.apply(lambda x: standerdize(x, word_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a8b495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_as.to_csv('../data/anglo_saxon.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723a8d32",
   "metadata": {},
   "source": [
    "# Norman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17a448d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nas = pd.read_csv('../data/EngOrdtext', delimiter='\\t', names=['text'])\n",
    "\n",
    "# read the date file\n",
    "# reshape the file in a format similar to the previous one\n",
    "date_nas = pd.read_csv('../data/EngOrdDate', delimiter=' ', header=None).values.ravel()\n",
    "date_nas = pd.DataFrame(date_nas, columns=['date']).dropna()\n",
    "\n",
    "id_nas = pd.read_csv('../data/EngOrdID', delimiter='\\t', names=['id'])\n",
    "\n",
    "# merge three df together to form a larger df contains both id, date, and text\n",
    "df_nas = pd.concat([id_nas, date_nas, text_nas], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "499b98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract first 10 words\n",
    "df_nas['phrase'] = df_nas.text.apply(lambda x: extract_10(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914e8600",
   "metadata": {},
   "source": [
    "# Standerdize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8262e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {\n",
    "    \"Radulfo\": [\"radulpo\", \"radulpho\"],\n",
    "    \"Ranulfo\": [\"ranulpo\", \"ranulpho\"],\n",
    "    \"hamoni\": [\"haimoni\"],\n",
    "    \"sampsoni\": [\"samsoni\"],\n",
    "    \"omnibus que\": [\"omnibusque\"],\n",
    "    \"londoniensi\": [\"lundoniensi\"],\n",
    "    \"toti que\": [\"totique\"],\n",
    "    \"gerardo\": [\"girardo\"],\n",
    "    \"norwic\": [\"nortwic\"],\n",
    "    \"rodbertus\": [\"rotbertus\"],\n",
    "    \"ranulfus\": [\"ranulpus\"],\n",
    "    \"gratia\": [\"gracia\"],\n",
    "    \"iesu\": [\"ihesu\"],\n",
    "    \"herefordensis\": [\"hereford\"],\n",
    "    \"teobaldus\": [\"teodbaldus\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3444053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nas.phrase = df_nas.phrase.apply(lambda x: standerdize(x, word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bed5269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nas.text = df_nas.text.apply(lambda x: standerdize(x, word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03e2c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nas.to_csv('../data/norman.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45449bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_as, df_nas], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e6370c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('../data/all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f416c8",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13826e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"../data/all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c93a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592167f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_preprocessing.plot_svd_performance(df_all.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
